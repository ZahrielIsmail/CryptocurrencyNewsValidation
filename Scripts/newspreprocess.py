# -*- coding: utf-8 -*-
"""NewsPreprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S9hLUG6egLKsIWiKRPISUIOrru4dplqa

Preprocessing Step (Extract Date and Article Theme)
"""

import pandas as pd
import re


sheets = pd.read_excel("Content.xlsx", sheet_name=None)
all_data = pd.DataFrame()

# Function to extract date from the Website URL
def extract_date_from_url(url):
    match = re.search(r'(\d{4})/(\d{2})/(\d{2})', url)
    if match:
        return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
    return None

def extract_theme_from_url(url):
    match = re.search(r'coindesk.com/([a-zA-Z\-]+)/', url)
    if match:
        return match.group(1)
    return None

processed_sheets = {}

for sheet_name, df in sheets.items():
    df['Date'] = df['Website'].apply(extract_date_from_url)
    df['Theme'] = df['Website'].apply(extract_theme_from_url)
    processed_sheets[sheet_name] = df
    all_data = pd.concat([all_data, df], ignore_index=True)



with pd.ExcelWriter('processed_content.xlsx') as writer:
    for sheet_name, df in processed_sheets.items():
        df.to_excel(writer, sheet_name=sheet_name, index=False)

print("Added Dates and Theme")

import matplotlib.pyplot as plt
import seaborn as sns

daily_counts = all_data.groupby('Date').size().reset_index(name='Article Count')

# Plot daily article counts
plt.figure(figsize=(27, 15))
sns.lineplot(x='Date', y='Article Count', data=daily_counts, marker="o")
plt.title('Number of Articles Posted Daily')
plt.xlabel('Date')
plt.ylabel('Article Count')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

theme_counts = all_data.groupby(['Date', 'Theme']).size().reset_index(name='Article Count')

plt.figure(figsize=(27, 15))
sns.lineplot(x='Date', y='Article Count', hue='Theme', data=theme_counts, marker="o")
plt.title('Number of Articles Posted Daily by Theme')
plt.xlabel('Date')
plt.ylabel('Article Count')
plt.xticks(rotation=45)
plt.grid(True)
plt.legend(title='Theme', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

import pandas as pd
import re

sheets = pd.read_excel("Content.xlsx", sheet_name=None)
all_data = pd.DataFrame()


def extract_date_from_url(url):
    match = re.search(r'(\d{4})/(\d{2})/(\d{2})', url)
    if match:
        return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
    return None


def extract_theme_from_url(url):
    match = re.search(r'coindesk.com/([a-zA-Z\-]+)/', url)
    if match:
        return match.group(1)
    return None


start_date = pd.to_datetime('2024-05-01')
end_date = pd.to_datetime('2024-07-31')

processed_sheets = {}
for sheet_name, df in sheets.items():
    df['Date'] = df['Website'].apply(extract_date_from_url)
    df['Theme'] = df['Website'].apply(extract_theme_from_url)
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    df_filtered = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]


    processed_sheets[sheet_name] = df_filtered
    all_data = pd.concat([all_data, df_filtered], ignore_index=True)


with pd.ExcelWriter('Filtered_Content.xlsx') as writer:
    for sheet_name, df in processed_sheets.items():
        df.to_excel(writer, sheet_name=sheet_name, index=False)

print("Preprocessing, filtering, and theme extraction completed. The processed file 'filtered_content_with_theme.xlsx' has been saved.")

import matplotlib.pyplot as plt
import seaborn as sns

daily_counts = all_data.groupby('Date').size().reset_index(name='Article Count')

# Plot daily article counts
plt.figure(figsize=(27, 15))
sns.lineplot(x='Date', y='Article Count', data=daily_counts, marker="o")
plt.title('Number of Articles Posted Daily')
plt.xlabel('Date')
plt.ylabel('Article Count')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

theme_counts = all_data.groupby(['Date', 'Theme']).size().reset_index(name='Article Count')

plt.figure(figsize=(27, 15))
sns.lineplot(x='Date', y='Article Count', hue='Theme', data=theme_counts, marker="o")
plt.title('Number of Articles Posted Daily by Theme')
plt.xlabel('Date')
plt.ylabel('Article Count')
plt.xticks(rotation=45)
plt.grid(True)
plt.legend(title='Theme', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

import pandas as pd
import re

sheets = pd.read_excel("Filtered_Content.xlsx", sheet_name=None)

unwanted_text = "This website uses cookies"

# Function to clean the 'SubHeader' column
def clean_subheader(subheader):
    if isinstance(subheader, str) and unwanted_text in subheader:
        # Remove the unwanted text from the 'SubHeader'
        return subheader.replace(unwanted_text, "").strip()
    return subheader

# Apply the function to clean the 'SubHeader' column
for sheet_name, df in sheets.items():
    df['SubHeader'] = df['SubHeader'].apply(clean_subheader)
    processed_sheets[sheet_name] = df

# Save the cleaned data back to an Excel file
cleaned_file_path = 'Cleaned_Content.xlsx'
df.to_excel(cleaned_file_path, index=False)

print(f"Cleaning completed '{cleaned_file_path}'.")

import pandas as pd

# Upload the Filtered_Content.xlsx file
from google.colab import files
uploaded = files.upload()

# Load the Excel file with the filtered data
file_path = 'Filtered_Content.xlsx'  # Replace with actual file name if different
df = pd.read_excel(file_path)

# Define the unwanted text to remove
unwanted_text = "This website uses cookies"

# Function to clean the 'SubHeader' column
def clean_subheader(subheader):
    if isinstance(subheader, str) and unwanted_text in subheader:
        # Remove the unwanted text from the 'SubHeader'
        return subheader.replace(unwanted_text, "").strip()
    return subheader

# Apply the function to clean the 'SubHeader' column
df['SubHeader'] = df['SubHeader'].apply(clean_subheader)

# Save the cleaned data back to an Excel file
cleaned_file_path = 'Cleaned_Filtered_Content.xlsx'
df.to_excel(cleaned_file_path, index=False)

print(f"Cleaning completed. The cleaned data has been saved to '{cleaned_file_path}'.")